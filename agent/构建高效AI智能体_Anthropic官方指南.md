# 构建高效AI智能体

*来源：Anthropic官方指南*  
*原文链接：https://www.anthropic.com/engineering/building-effective-agents*

## 引言

在过去的一年中，我们与数十个跨行业构建大语言模型(LLM)智能体的团队合作。令人一致的发现是，最成功的实现并不是使用复杂的框架或专门的库，而是使用简单、可组合的模式来构建。

在这篇文章中，我们分享了与客户合作和自主构建智能体过程中学到的经验，并为开发者提供构建高效智能体的实用建议。

## 什么是智能体？

"智能体"可以有多种定义。一些客户将智能体定义为完全自主的系统，能够在较长时间内独立运行，使用各种工具完成复杂任务。其他人则使用这个术语来描述遵循预定义工作流程的更具规范性的实现。在Anthropic，我们将所有这些变体归类为智能体系统，但在工作流和智能体之间做出重要的架构区分：

- **工作流**是通过预定义代码路径编排LLM和工具的系统。
- **智能体**是LLM动态指导自己的流程和工具使用，保持对如何完成任务的控制的系统。

下面，我们将详细探讨这两种类型的智能体系统。在附录1（"实践中的智能体"）中，我们描述了客户发现使用这些系统特别有价值的两个领域。

## 何时使用（以及何时不使用）智能体

在使用LLM构建应用程序时，我们建议找到最简单的解决方案，只有在需要时才增加复杂性。这可能意味着根本不构建智能体系统。智能体系统通常以延迟和成本换取更好的任务性能，你应该考虑这种权衡何时有意义。

当需要更多复杂性时，工作流为明确定义的任务提供可预测性和一致性，而当需要灵活性和模型驱动的大规模决策制定时，智能体是更好的选择。然而，对于许多应用程序，优化带有检索和上下文示例的单个LLM调用通常就足够了。

## 何时以及如何使用框架

有许多框架使智能体系统更容易实现，包括：

- LangChain的LangGraph
- Amazon Bedrock的AI智能体框架
- Rivet，一个拖拽式GUI LLM工作流构建器
- Vellum，另一个用于构建和测试复杂工作流的GUI工具

这些框架通过简化标准的低级任务（如调用LLM、定义和解析工具以及链式调用）使入门变得容易。然而，它们通常会创建额外的抽象层，可能会掩盖底层的提示和响应，使调试变得更困难。它们也可能在简单设置足够时让人倾向于增加复杂性。

我们建议开发者从直接使用LLM API开始：许多模式可以用几行代码实现。如果你确实使用框架，请确保你理解底层代码。对底层原理的错误假设是客户错误的常见来源。

查看我们的cookbook获取一些示例实现。

## 构建块、工作流和智能体

在本节中，我们将探索我们在生产中看到的智能体系统的常见模式。我们将从基础构建块——增强型LLM开始，逐步增加复杂性，从简单的组合工作流到自主智能体。

### 构建块：增强型LLM

智能体系统的基本构建块是通过检索、工具和记忆等增强功能加强的LLM。我们当前的模型可以主动使用这些能力——生成自己的搜索查询、选择适当的工具并确定要保留的信息。

![增强型LLM示意图](https://www-cdn.anthropic.com/images/4zrzovbb/website/d3083d3f40bb2b6f477901cc9a240738d3dd1371-2401x1000.png)

我们建议专注于实现的两个关键方面：将这些能力定制到你的特定用例，并确保它们为你的LLM提供简单、文档完善的接口。虽然有许多方法来实现这些增强功能，但一种方法是通过我们最近发布的模型上下文协议，它允许开发者通过简单的客户端实现与不断增长的第三方工具生态系统集成。

对于这篇文章的其余部分，我们假设每个LLM调用都有这些增强能力的访问权限。

### 工作流：提示链

提示链将任务分解为一系列步骤，其中每个LLM调用处理前一个的输出。你可以在任何中间步骤添加程序化检查（见下图中的"gate"）以确保过程仍在正轨上。

![提示链工作流示意图](https://www-cdn.anthropic.com/images/4zrzovbb/website/7418719e3dab222dccb379b8879e1dc08ad34c78-2401x1000.png)

**何时使用此工作流**：此工作流适用于任务可以轻松且清晰地分解为固定子任务的情况。主要目标是通过使每个LLM调用成为更容易的任务来权衡延迟以获得更高的准确性。

**提示链有用的示例**：
- 生成营销文案，然后将其翻译成不同的语言
- 写文档大纲，检查大纲是否符合某些标准，然后基于大纲写文档

### 工作流：路由

路由对输入进行分类并将其引导到专门的后续任务。此工作流允许关注点分离和构建更专门的提示。没有此工作流，为一种输入类型的优化可能会损害其他输入的性能。

![路由工作流示意图](https://www-cdn.anthropic.com/images/4zrzovbb/website/5c0c0e9fe4def0b584c04d37849941da55e5e71c-2401x1000.png)

**何时使用此工作流**：路由适用于有明确类别且最好分别处理的复杂任务，以及分类可以准确处理的情况，无论是通过LLM还是更传统的分类模型/算法。

**路由有用的示例**：
- 将不同类型的客户服务查询（一般问题、退款请求、技术支持）引导到不同的下游流程、提示和工具
- 将简单/常见问题路由到较小的模型如Claude 3.5 Haiku，将困难/不寻常的问题路由到更强大的模型如Claude 3.5 Sonnet以优化成本和速度

### 工作流：并行化

LLM有时可以同时处理任务并以程序化方式聚合其输出。这种工作流——并行化——表现为两种关键变体：

- **分段**：将任务分解为独立的并行子任务
- **投票**：多次运行相同任务以获得多样化的输出

![并行化工作流示意图](https://www-cdn.anthropic.com/images/4zrzovbb/website/406bb032ca007fd1624f261af717d70e6ca86286-2401x1000.png)

**何时使用此工作流**：当划分的子任务可以并行化以提高速度，或者需要多个视角或尝试以获得更高置信度结果时，并行化是有效的。对于具有多重考虑的复杂任务，LLM通常在每个考虑由单独的LLM调用处理时表现更好，允许对每个特定方面进行专注的关注。

**并行化有用的示例**：

**分段**：
- 实现护栏，其中一个模型实例处理用户查询，而另一个筛选不当内容或请求。这往往比让同一个LLM调用同时处理护栏和核心响应表现更好
- 自动化评估以评估LLM性能，其中每个LLM调用评估模型在给定提示上性能的不同方面

**投票**：
- 审查代码漏洞，其中多个不同的提示审查代码并在发现问题时标记
- 评估给定内容是否不当，多个提示评估不同方面或需要不同的投票阈值来平衡误报和漏报

### 工作流：编排者-工作者

在编排者-工作者工作流中，中央LLM动态分解任务，将其委派给工作者LLM，并综合其结果。

![编排者-工作者工作流示意图](https://www-cdn.anthropic.com/images/4zrzovbb/website/8985fc683fae4780fb34eab1365ab78c7e51bc8e-2401x1000.png)

**何时使用此工作流**：此工作流适合无法预测所需子任务的复杂任务（例如，在编码中，需要更改的文件数量和每个文件中更改的性质可能取决于任务）。虽然在拓扑上相似，但与并行化的关键区别在于其灵活性——子任务不是预定义的，而是由编排者根据特定输入确定的。

**编排者-工作者有用的示例**：
- 每次对多个文件进行复杂更改的编码产品
- 涉及从多个来源收集和分析信息以获取可能相关信息的搜索任务

### 工作流：评估器-优化器

在评估器-优化器工作流中，一个LLM调用生成响应，而另一个在循环中提供评估和反馈。

![评估器-优化器工作流示意图](https://www-cdn.anthropic.com/images/4zrzovbb/website/14f51e6406ccb29e695da48b17017e899a6119c7-2401x1000.png)

**何时使用此工作流**：当我们有明确的评估标准，以及迭代改进提供可衡量价值时，此工作流特别有效。良好适配的两个标志是，首先，当人类表达反馈时LLM响应可以明显改善；其次，LLM可以提供这样的反馈。这类似于人类作家在制作精美文档时可能经历的迭代写作过程。

**评估器-优化器有用的示例**：
- 文学翻译，其中翻译器LLM最初可能无法捕捉到细节，但评估器LLM可以提供有用的批评
- 需要多轮搜索和分析以收集综合信息的复杂搜索任务，其中评估器决定是否需要进一步搜索

## 智能体

随着LLM在关键能力方面的成熟——理解复杂输入、进行推理和规划、可靠地使用工具以及从错误中恢复——智能体正在生产中出现。智能体开始工作时，要么接受人类用户的命令，要么与人类用户进行互动讨论。一旦任务明确，智能体就会独立规划和操作，可能会返回人类那里获取进一步信息或判断。

在执行过程中，智能体在每一步从环境中获得"基础真相"（如工具调用结果或代码执行）以评估其进展是至关重要的。然后智能体可以在检查点或遇到阻塞时暂停以获取人类反馈。任务通常在完成时终止，但包含停止条件（如最大迭代次数）以保持控制也很常见。

![自主智能体示意图](https://www-cdn.anthropic.com/images/4zrzovbb/website/58d9f10c985c4eb5d53798dea315f7bb5ab6249e-2401x1000.png)

智能体可以处理复杂任务，但它们的实现通常很直接。它们通常只是在循环中基于环境反馈使用工具的LLM。因此，清晰和周到地设计工具集及其文档是至关重要的。我们在附录2（"提示工程你的工具"）中扩展了工具开发的最佳实践。

**何时使用智能体**：智能体可以用于开放式问题，其中难以或不可能预测所需的步骤数，并且你无法硬编码固定路径。LLM将可能运行许多回合，你必须对其决策制定有一定程度的信任。智能体的自主性使它们非常适合在受信任环境中扩展任务。

智能体的自主性意味着更高的成本和累积错误的潜力。我们建议在沙盒环境中进行广泛测试，以及适当的护栏。

**智能体有用的示例**：

以下示例来自我们自己的实现：
- 解决SWE-bench任务的编码智能体，涉及基于任务描述对许多文件进行编辑
- 我们的"计算机使用"参考实现，其中Claude使用计算机完成任务

![编码智能体的高级流程图](https://www-cdn.anthropic.com/images/4zrzovbb/website/4b9a1f4eb63d5962a6e1746ac26bbc857cf3474f-2400x1666.png)

## 组合和定制这些模式

这些构建块不是规范性的。它们是开发者可以塑造和组合以适应不同用例的常见模式。成功的关键，如同任何LLM功能一样，是衡量性能并迭代实现。重申一下：你应该只有在明显改善结果时才考虑增加复杂性。

## 总结

LLM领域的成功不在于构建最复杂的系统，而在于构建适合你需求的正确系统。从简单提示开始，通过全面评估优化它们，只有在简单解决方案不足时才添加多步骤智能体系统。

在实现智能体时，我们尝试遵循三个核心原则：

1. **保持智能体设计的简单性**
2. **通过明确显示智能体的规划步骤来优先考虑透明度**
3. **通过彻底的工具文档和测试精心设计你的智能体-计算机接口(ACI)**

框架可以帮助你快速开始，但当你进入生产时，不要犹豫减少抽象层并使用基本组件构建。通过遵循这些原则，你可以创建不仅强大而且可靠、可维护并受用户信任的智能体。

## 致谢

本文由Erik Schluntz和Barry Zhang撰写。这项工作借鉴了我们在Anthropic构建智能体的经验以及客户分享的宝贵见解，我们对此深表感谢。

## 附录1：实践中的智能体

我们与客户的合作揭示了AI智能体的两个特别有前景的应用，这些应用展示了上述讨论模式的实用价值。这两个应用都说明了智能体如何为需要对话和行动、有明确成功标准、启用反馈循环并整合有意义人类监督的任务增加最大价值。

### A. 客户支持

客户支持将熟悉的聊天机器人界面与通过工具集成增强的功能相结合。这对于更开放式的智能体来说是自然的匹配，因为：

- 支持交互自然遵循对话流程，同时需要访问外部信息和行动
- 工具可以集成以提取客户数据、订单历史和知识库文章
- 诸如发放退款或更新票据等行动可以程序化处理
- 成功可以通过用户定义的解决方案清楚地衡量

几家公司通过基于使用的定价模型展示了这种方法的可行性，该模型仅对成功解决收费，显示了对其智能体有效性的信心。

### B. 编码智能体

软件开发领域显示了LLM功能的巨大潜力，能力从代码补全发展到自主问题解决。智能体特别有效，因为：

- 代码解决方案可以通过自动化测试验证
- 智能体可以使用测试结果作为反馈迭代解决方案
- 问题空间定义明确且结构化
- 输出质量可以客观衡量

在我们自己的实现中，智能体现在可以仅基于拉取请求描述解决SWE-bench Verified基准测试中的真实GitHub问题。然而，虽然自动化测试有助于验证功能，但人类审查对于确保解决方案符合更广泛的系统要求仍然至关重要。

## 附录2：提示工程你的工具

无论你正在构建哪种智能体系统，工具可能都将是你智能体的重要组成部分。工具通过在我们的API中指定其确切结构和定义，使Claude能够与外部服务和API交互。当Claude响应时，如果它计划调用工具，它将在API响应中包含工具使用块。

工具定义和规范应该像你的整体提示一样受到提示工程的关注。在这个简短的附录中，我们描述如何对你的工具进行提示工程。

通常有几种方法来指定同一行动。例如，你可以通过写差异或重写整个文件来指定文件编辑。对于结构化输出，你可以在markdown或JSON内返回代码。在软件工程中，这样的差异是表面的，可以无损地从一种转换为另一种。然而，某些格式对LLM来说比其他格式更难写。

写差异需要在编写新代码之前知道块头中正在改变多少行。在JSON内写代码（与markdown相比）需要额外转义换行符和引号。

我们对决定工具格式的建议如下：

- 给模型足够的标记在将自己写入困境之前进行"思考"
- 保持格式接近模型在互联网文本中自然看到的内容
- 确保没有格式"开销"，如必须保持数千行代码的准确计数，或字符串转义任何它写的代码

一个经验法则是考虑人机界面(HCI)需要多少努力，并计划在创建良好的智能体-计算机接口(ACI)上投入同样多的努力。以下是一些关于如何做到这一点的想法：

**站在模型的角度思考**：基于描述和参数，使用这个工具是否明显，或者你需要仔细思考吗？如果是这样，那么对模型来说可能也是如此。一个好的工具定义通常包括示例使用、边缘情况、输入格式要求以及与其他工具的明确界限。

**如何更改参数名称或描述以使事情更明显？** 把这想象成为你团队中的初级开发者写一个很棒的文档字符串。当使用许多相似工具时，这特别重要。

**测试模型如何使用你的工具**：在我们的工作台中运行许多示例输入，看看模型犯了什么错误，并迭代。

**防错你的工具**：更改参数，使犯错误变得更难。

在为SWE-bench构建我们的智能体时，我们实际上花费了更多时间优化我们的工具，而不是整体提示。例如，我们发现模型在智能体移出根目录后会对使用相对文件路径的工具犯错误。为了解决这个问题，我们更改了工具以始终需要绝对文件路径——我们发现模型完美地使用了这种方法。