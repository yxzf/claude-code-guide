#!/usr/bin/env python3
"""
æ™ºèƒ½æŠ•èµ„åˆ†æAgent
è‡ªåŠ¨åŒ–åˆ†æçŸ¥è¯†æ˜Ÿçƒæ”¶è—çš„æŠ•èµ„å†…å®¹ï¼Œç”Ÿæˆç»“æ„åŒ–æŠ•èµ„åˆ†ææŠ¥å‘Š
"""

import json
import re
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from pathlib import Path
import os

@dataclass
class PostData:
    """å¸–å­æ•°æ®ç»“æ„"""
    content: str
    timestamp: str
    date: str
    source: str
    title: str
    author: str = ""

class InvestmentAnalysisAgent:
    """æ™ºèƒ½æŠ•èµ„åˆ†æAgent"""

    def __init__(self, output_dir: str = "./investment_analysis"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.posts_data: List[PostData] = []
        self.date_range: tuple = None

    def extract_posts_from_favorites(self, start_date: str, end_date: str) -> List[PostData]:
        """
        ä»çŸ¥è¯†æ˜Ÿçƒæ”¶è—å¤¹æå–å¸–å­æ•°æ®

        Args:
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)

        Returns:
            List[PostData]: æå–çš„å¸–å­æ•°æ®åˆ—è¡¨
        """
        print(f"ğŸš€ å¼€å§‹æå– {start_date} åˆ° {end_date} çš„æ”¶è—å†…å®¹...")

        # è¿™é‡Œæ˜¯å¯¹åº”çš„MCP Chromeè°ƒç”¨é€»è¾‘çš„Pythonè¡¨ç¤º
        # å®é™…æ‰§è¡Œæ—¶éœ€è¦é€šè¿‡Claude Codeçš„toolè°ƒç”¨

        extraction_steps = [
            "1. è®¿é—®çŸ¥è¯†æ˜Ÿçƒæ”¶è—å¤¹: https://wx.zsxq.com/favorites",
            "2. ç³»ç»Ÿæ€§æå–æ‰€æœ‰å¸–å­å†…å®¹",
            "3. è§£ææ¯ä¸ªå¸–å­çš„è¯¦ç»†ä¿¡æ¯",
            "4. æŒ‰æ—¥æœŸèŒƒå›´è¿‡æ»¤å¸–å­",
            "5. æ„å»ºPostDataå¯¹è±¡åˆ—è¡¨"
        ]

        # ç¤ºä¾‹æ•°æ®ç»“æ„ - å®é™…ä½¿ç”¨æ—¶é€šè¿‡MCP Chromeå·¥å…·è·å–
        sample_posts = [
            PostData(
                content="ç¤ºä¾‹æŠ•èµ„åˆ†æå†…å®¹...",
                timestamp="2025-09-14 20:30",
                date="2025-09-14",
                source="åŸºä¸šé•¿è™¹1.0",
                title="ç¤ºä¾‹æŠ•èµ„ä¸»é¢˜",
                author="åˆ†æå¸ˆ"
            )
        ]

        return self._filter_posts_by_date(sample_posts, start_date, end_date)

    def _filter_posts_by_date(self, posts: List[PostData], start_date: str, end_date: str) -> List[PostData]:
        """æŒ‰æ—¥æœŸèŒƒå›´è¿‡æ»¤å¸–å­"""
        start_dt = datetime.strptime(start_date, "%Y-%m-%d")
        end_dt = datetime.strptime(end_date, "%Y-%m-%d")

        filtered_posts = []
        for post in posts:
            try:
                post_dt = datetime.strptime(post.date, "%Y-%m-%d")
                if start_dt <= post_dt <= end_dt:
                    filtered_posts.append(post)
            except ValueError:
                continue

        return filtered_posts

    def group_posts_by_date(self, posts: List[PostData]) -> Dict[str, List[PostData]]:
        """æŒ‰æ—¥æœŸåˆ†ç»„å¸–å­"""
        grouped = {}
        for post in posts:
            date = post.date
            if date not in grouped:
                grouped[date] = []
            grouped[date].append(post)
        return grouped

    def analyze_daily_themes(self, posts: List[PostData]) -> Dict[str, Any]:
        """åˆ†æå•æ—¥æŠ•èµ„ä¸»é¢˜"""
        if not posts:
            return {}

        # æå–å…³é”®è¯å’Œä¸»é¢˜
        themes = self._extract_investment_themes(posts)
        companies = self._extract_company_mentions(posts)
        technologies = self._extract_technology_trends(posts)

        analysis = {
            "post_count": len(posts),
            "main_themes": themes,
            "key_companies": companies,
            "technology_trends": technologies,
            "investment_logic": self._generate_investment_logic(posts),
            "risk_factors": self._identify_risk_factors(posts)
        }

        return analysis

    def _extract_investment_themes(self, posts: List[PostData]) -> List[str]:
        """æå–æŠ•èµ„ä¸»é¢˜"""
        theme_keywords = {
            "åŒ»ç–—è®¾å¤‡": ["åŒ»ç–—è®¾å¤‡", "å™¨æ¢°", "è”å½±", "è¿ˆç‘", "å¼€ç«‹"],
            "å›½äº§ç®—åŠ›": ["ç®—åŠ›", "èŠ¯ç‰‡", "AI", "GPU", "å¯’æ­¦çºª", "æµ·å…‰"],
            "å…‰é€šä¿¡": ["å…‰é€šä¿¡", "å…‰æ¨¡å—", "CPO", "ç››ç§‘é€šä¿¡", "ç½‘ç»œè®¾å¤‡"],
            "å­˜å‚¨èŠ¯ç‰‡": ["å­˜å‚¨", "HBM", "DDR", "é—ªå­˜", "å…†æ˜“åˆ›æ–°"],
            "æ–°èƒ½æº": ["æ–°èƒ½æº", "é”‚ç”µ", "å…‰ä¼", "é£ç”µ", "å‚¨èƒ½"],
            "å†›å·¥": ["å†›å·¥", "å›½é˜²", "èˆªç©º", "èˆªå¤©", "é›·è¾¾"]
        }

        detected_themes = []
        all_content = " ".join([post.content for post in posts])

        for theme, keywords in theme_keywords.items():
            for keyword in keywords:
                if keyword in all_content:
                    detected_themes.append(theme)
                    break

        return list(set(detected_themes))

    def _extract_company_mentions(self, posts: List[PostData]) -> List[str]:
        """æå–å…¬å¸æåŠ"""
        # ç®€åŒ–çš„å…¬å¸åç§°æå–é€»è¾‘
        company_pattern = r'([A-Z][a-z]+(?:[A-Z][a-z]+)*|[\u4e00-\u9fff]+(?:è‚¡ä»½|ç§‘æŠ€|åŒ»ç–—|åŒ»è¯|ç”µå­|é€šä¿¡|æ–°ææ–™|æ™ºèƒ½|æ•°æ®|ç½‘ç»œ|ç³»ç»Ÿ|è£…å¤‡|åˆ¶é€ |å·¥ä¸š|èƒ½æº|ç¯ä¿))'

        companies = set()
        for post in posts:
            matches = re.findall(company_pattern, post.content)
            companies.update(matches)

        return list(companies)[:10]  # è¿”å›å‰10ä¸ª

    def _extract_technology_trends(self, posts: List[PostData]) -> List[str]:
        """æå–æŠ€æœ¯è¶‹åŠ¿"""
        tech_keywords = [
            "AI", "äººå·¥æ™ºèƒ½", "æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ ",
            "5G", "6G", "ç‰©è”ç½‘", "è¾¹ç¼˜è®¡ç®—",
            "CPO", "ç¡…å…‰", "å…‰å­", "é‡å­",
            "HBM", "DDR5", "å­˜ç®—ä¸€ä½“",
            "æ–°èƒ½æº", "å‚¨èƒ½", "æ°¢èƒ½", "ç¢³ä¸­å’Œ"
        ]

        detected_tech = []
        all_content = " ".join([post.content for post in posts])

        for tech in tech_keywords:
            if tech in all_content:
                detected_tech.append(tech)

        return detected_tech

    def _generate_investment_logic(self, posts: List[PostData]) -> str:
        """ç”ŸæˆæŠ•èµ„é€»è¾‘"""
        themes = self._extract_investment_themes(posts)
        if not themes:
            return "æš‚æ— æ˜ç¡®æŠ•èµ„ä¸»é¢˜"

        logic_templates = {
            "åŒ»ç–—è®¾å¤‡": "åŒ»ç–—è®¾å¤‡è¡Œä¸šå—ç›Šäºæ‹›æ ‡å›æš–å’Œæµ·å¤–å¸‚åœºæ‹“å±•ï¼ŒQ3æœ‰æœ›è¿æ¥ä¸šç»©æ‹ç‚¹",
            "å›½äº§ç®—åŠ›": "å›½äº§ç®—åŠ›è¿æ¥äº§ä¸šåŒ–æ‹ç‚¹ï¼Œæ”¿ç­–æ”¯æŒåŠ›åº¦åŠ å¤§ï¼ŒæŠ€æœ¯çªç ´å¸¦æ¥æŠ•èµ„æœºä¼š",
            "å…‰é€šä¿¡": "AIç®—åŠ›éœ€æ±‚é©±åŠ¨å…‰é€šä¿¡æŠ€æœ¯å‡çº§ï¼ŒCPOç­‰å‰æ²¿æŠ€æœ¯äº§ä¸šåŒ–æé€Ÿ",
            "å­˜å‚¨èŠ¯ç‰‡": "å­˜å‚¨èŠ¯ç‰‡æ¶¨ä»·è¶‹åŠ¿æ˜ç¡®ï¼Œå›½äº§æ›¿ä»£å’ŒæŠ€æœ¯å‡çº§åŒé‡é©±åŠ¨"
        }

        main_theme = themes[0] if themes else "ç»¼åˆ"
        return logic_templates.get(main_theme, "å¤šå…ƒåŒ–æŠ•èµ„æœºä¼šï¼Œå…³æ³¨æŠ€æœ¯åˆ›æ–°å’Œæ”¿ç­–å‚¬åŒ–")

    def _identify_risk_factors(self, posts: List[PostData]) -> List[str]:
        """è¯†åˆ«é£é™©å› ç´ """
        risk_keywords = [
            ("æ”¿ç­–é£é™©", ["æ”¿ç­–", "ç›‘ç®¡", "é›†é‡‡", "è´¸æ˜“æ‘©æ“¦"]),
            ("æŠ€æœ¯é£é™©", ["æŠ€æœ¯", "ç ”å‘", "åˆ›æ–°", "çªç ´"]),
            ("å¸‚åœºé£é™©", ["ç«äº‰", "å¸‚åœº", "éœ€æ±‚", "æ™¯æ°”åº¦"]),
            ("ä¼°å€¼é£é™©", ["ä¼°å€¼", "æ³¡æ²«", "é«˜ä½", "å›è°ƒ"])
        ]

        identified_risks = []
        all_content = " ".join([post.content for post in posts])

        for risk_type, keywords in risk_keywords:
            if any(keyword in all_content for keyword in keywords):
                identified_risks.append(risk_type)

        return identified_risks

    def generate_daily_report(self, date: str, posts: List[PostData], analysis: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ—¥åº¦æŠ•èµ„åˆ†ææŠ¥å‘Š"""
        report_template = f"""# {date}æŠ•èµ„æ”¶è—åˆ†æ

## ğŸ“… æ—¥æœŸï¼š{date}
**æ”¶è—æ•°é‡**ï¼š{analysis['post_count']}ä¸ªå¸–å­
**ä¸»è¦ä¸»é¢˜**ï¼š{', '.join(analysis['main_themes']) if analysis['main_themes'] else 'ç»¼åˆæŠ•èµ„'}

---

## ğŸ“Š æ ¸å¿ƒå†…å®¹æ‘˜è¦

### ğŸ¯ ä¸»è¦æŠ•èµ„ä¸»é¢˜
{self._format_themes_section(analysis['main_themes'], posts)}

### ğŸ¢ é‡ç‚¹å…³æ³¨å…¬å¸
{self._format_companies_section(analysis['key_companies'])}

### ğŸš€ æŠ€æœ¯è¶‹åŠ¿
{self._format_tech_section(analysis['technology_trends'])}

---

## ğŸ’¡ æŠ•èµ„ç­–ç•¥åˆ†æ

### ğŸ“ˆ æŠ•èµ„é€»è¾‘
{analysis['investment_logic']}

### âš ï¸ é£é™©æç¤º
{self._format_risks_section(analysis['risk_factors'])}

### ğŸ¯ æŠ•èµ„å»ºè®®
{self._generate_investment_advice(analysis)}

---

## ğŸ“‹ è¯¦ç»†å†…å®¹åˆ—è¡¨

{self._format_posts_detail(posts)}

---
*åˆ†ææ—¶é—´: {datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")}*
*æ•°æ®æ¥æº: çŸ¥è¯†æ˜Ÿçƒæ”¶è—å†…å®¹*
"""
        return report_template

    def _format_themes_section(self, themes: List[str], posts: List[PostData]) -> str:
        """æ ¼å¼åŒ–ä¸»é¢˜éƒ¨åˆ†"""
        if not themes:
            return "- ç»¼åˆæŠ•èµ„ä¸»é¢˜ï¼Œæ¶µç›–å¤šä¸ªè¡Œä¸šé¢†åŸŸ"

        section = ""
        for i, theme in enumerate(themes, 1):
            section += f"\n#### {i}. {theme}\n"
            section += f"- **æŠ•èµ„é€»è¾‘**: {self._get_theme_logic(theme)}\n"
            section += f"- **å…³é”®å‚¬åŒ–å‰‚**: {self._get_theme_catalysts(theme)}\n"

        return section

    def _format_companies_section(self, companies: List[str]) -> str:
        """æ ¼å¼åŒ–å…¬å¸éƒ¨åˆ†"""
        if not companies:
            return "- æš‚æ— æ˜ç¡®é‡ç‚¹å…¬å¸æåŠ"

        return "\n".join([f"- **{company}**" for company in companies[:8]])

    def _format_tech_section(self, technologies: List[str]) -> str:
        """æ ¼å¼åŒ–æŠ€æœ¯éƒ¨åˆ†"""
        if not technologies:
            return "- æš‚æ— æ˜ç¡®æŠ€æœ¯è¶‹åŠ¿"

        return "\n".join([f"- {tech}" for tech in technologies])

    def _format_risks_section(self, risks: List[str]) -> str:
        """æ ¼å¼åŒ–é£é™©éƒ¨åˆ†"""
        if not risks:
            return "1. å¸‚åœºé£é™©ï¼šæ•´ä½“å¸‚åœºæ³¢åŠ¨å½±å“\n2. è¡Œä¸šé£é™©ï¼šè¡Œä¸šæ™¯æ°”åº¦å˜åŒ–"

        return "\n".join([f"{i+1}. {risk}" for i, risk in enumerate(risks)])

    def _format_posts_detail(self, posts: List[PostData]) -> str:
        """æ ¼å¼åŒ–å¸–å­è¯¦ç»†åˆ—è¡¨"""
        if not posts:
            return "æš‚æ— å…·ä½“å†…å®¹"

        details = ""
        for i, post in enumerate(posts, 1):
            details += f"\n### å¸–å­{i}ï¼š{post.title or 'æŠ•èµ„åˆ†æ'}\n"
            details += f"**æ—¶é—´**: {post.timestamp}\n"
            details += f"**æ¥æº**: {post.source}\n"
            details += f"**æ‘˜è¦**: {post.content[:200]}...\n"

        return details

    def _get_theme_logic(self, theme: str) -> str:
        """è·å–ä¸»é¢˜æŠ•èµ„é€»è¾‘"""
        logic_map = {
            "åŒ»ç–—è®¾å¤‡": "æ‹›æ ‡æ•°æ®å›æš–ï¼ŒQ3æœ‰æœ›è¿æ¥ä¸šç»©æ‹ç‚¹ï¼Œæµ·å¤–å¸‚åœºå¿«é€Ÿæ‹“å±•",
            "å›½äº§ç®—åŠ›": "å…ˆè¿›åˆ¶ç¨‹äº§èƒ½æ‰©å¼ ï¼Œæ”¿ç­–æ”¯æŒåŠ›åº¦åŠ å¤§ï¼Œäº§ä¸šåŒ–æ‹ç‚¹æ˜¾ç°",
            "å…‰é€šä¿¡": "AIç®—åŠ›éœ€æ±‚é©±åŠ¨æŠ€æœ¯å‡çº§ï¼ŒCPOç­‰å‰æ²¿æŠ€æœ¯äº§ä¸šåŒ–åŠ é€Ÿ",
            "å­˜å‚¨èŠ¯ç‰‡": "ä¾›éœ€æ ¼å±€æ”¹å–„ï¼Œå›½äº§æ›¿ä»£æ·±åŒ–ï¼ŒæŠ€æœ¯åˆ›æ–°å¸¦æ¥å¢é‡å¸‚åœº"
        }
        return logic_map.get(theme, "æŠ€æœ¯åˆ›æ–°é©±åŠ¨ï¼Œæ”¿ç­–æ”¯æŒï¼Œå¸‚åœºéœ€æ±‚å¢é•¿")

    def _get_theme_catalysts(self, theme: str) -> str:
        """è·å–ä¸»é¢˜å‚¬åŒ–å‰‚"""
        catalyst_map = {
            "åŒ»ç–—è®¾å¤‡": "Q3è´¢æŠ¥éªŒè¯ï¼Œæµ·å¤–è®¢å•è½åœ°ï¼Œè®¾å¤‡æ›´æ–°æ”¿ç­–",
            "å›½äº§ç®—åŠ›": "æ”¿ç­–å‚¬åŒ–å¯†é›†æœŸï¼Œå…ˆè¿›åˆ¶ç¨‹äº§èƒ½é‡Šæ”¾ï¼Œå›½äº§æ›¿ä»£åŠ é€Ÿ",
            "å…‰é€šä¿¡": "AIåº”ç”¨çˆ†å‘ï¼ŒæŠ€æœ¯æ ‡å‡†ç¡®ç«‹ï¼Œ5Gå»ºè®¾æé€Ÿ",
            "å­˜å‚¨èŠ¯ç‰‡": "æ¶¨ä»·è¶‹åŠ¿å»¶ç»­ï¼Œæ–°æŠ€æœ¯é‡äº§ï¼Œä¸‹æ¸¸éœ€æ±‚å›æš–"
        }
        return catalyst_map.get(theme, "æ”¿ç­–æ”¯æŒï¼ŒæŠ€æœ¯çªç ´ï¼Œå¸‚åœºéœ€æ±‚")

    def _generate_investment_advice(self, analysis: Dict[str, Any]) -> str:
        """ç”ŸæˆæŠ•èµ„å»ºè®®"""
        themes = analysis['main_themes']
        if not themes:
            return "å»ºè®®å…³æ³¨å¸‚åœºçƒ­ç‚¹è½®åŠ¨ï¼Œä¿æŒé€‚åº¦åˆ†æ•£é…ç½®"

        advice = "**é…ç½®å»ºè®®**:\n"
        for theme in themes:
            weight = self._get_theme_weight(theme)
            advice += f"- {theme}æ¿å— ({weight}) - {self._get_theme_strategy(theme)}\n"

        return advice

    def _get_theme_weight(self, theme: str) -> str:
        """è·å–ä¸»é¢˜æƒé‡å»ºè®®"""
        weight_map = {
            "åŒ»ç–—è®¾å¤‡": "25-30%",
            "å›½äº§ç®—åŠ›": "20-25%",
            "å…‰é€šä¿¡": "15-20%",
            "å­˜å‚¨èŠ¯ç‰‡": "10-15%"
        }
        return weight_map.get(theme, "5-10%")

    def _get_theme_strategy(self, theme: str) -> str:
        """è·å–ä¸»é¢˜ç­–ç•¥"""
        strategy_map = {
            "åŒ»ç–—è®¾å¤‡": "å…³æ³¨Q3ä¸šç»©æ‹ç‚¹ï¼Œé‡ç‚¹é…ç½®é¾™å¤´ä¼ä¸š",
            "å›½äº§ç®—åŠ›": "æŠŠæ¡æ”¿ç­–å‚¬åŒ–ï¼Œå…³æ³¨æŠ€æœ¯çªç ´æ ‡çš„",
            "å…‰é€šä¿¡": "èšç„¦AIé©±åŠ¨éœ€æ±‚ï¼Œå…³æ³¨æŠ€æœ¯åˆ›æ–°å…¬å¸",
            "å­˜å‚¨èŠ¯ç‰‡": "å…³æ³¨æ¶¨ä»·å—ç›Šæ ‡çš„ï¼Œå¸ƒå±€æŠ€æœ¯å‡çº§"
        }
        return strategy_map.get(theme, "å…³æ³¨é¾™å¤´ä¼ä¸šï¼Œé€‚åº¦é…ç½®")

    def create_comprehensive_summary(self, date_range: tuple, all_analysis: Dict[str, Dict]) -> str:
        """åˆ›å»ºç»¼åˆæŠ•èµ„ç­–ç•¥æ±‡æ€»"""
        start_date, end_date = date_range

        # æ±‡æ€»æ‰€æœ‰ä¸»é¢˜
        all_themes = set()
        all_companies = set()
        all_risks = set()

        for daily_analysis in all_analysis.values():
            all_themes.update(daily_analysis.get('main_themes', []))
            all_companies.update(daily_analysis.get('key_companies', []))
            all_risks.update(daily_analysis.get('risk_factors', []))

        summary_template = f"""# {start_date}è‡³{end_date}æŠ•èµ„æ”¶è—ç»¼åˆæ±‡æ€»

## ğŸ“… åˆ†æå‘¨æœŸï¼š{start_date} - {end_date}
**æ•°æ®æ¥æº**ï¼šåŸºä¸šé•¿è™¹1.0çŸ¥è¯†æ˜Ÿçƒæ”¶è—å†…å®¹
**åˆ†ææ—¶é—´**ï¼š{datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")}

---

## ğŸ¯ æ ¸å¿ƒæŠ•èµ„ä¸»é¢˜æ€»ç»“

{self._format_comprehensive_themes(all_themes)}

---

## ğŸ’° ç»¼åˆæŠ•èµ„é…ç½®ç­–ç•¥

{self._format_comprehensive_strategy(all_themes)}

---

## ğŸ¢ é‡ç‚¹å…³æ³¨æ ‡çš„

{self._format_comprehensive_companies(list(all_companies)[:15])}

---

## âš ï¸ é£é™©æç¤ºä¸åº”å¯¹

{self._format_comprehensive_risks(list(all_risks))}

---

## ğŸ“ˆ åç»­è·Ÿè¸ªè¦ç‚¹

{self._generate_tracking_points(all_themes)}

---

## ğŸ¯ æ€»ç»“

{self._generate_comprehensive_conclusion(all_themes, date_range)}

---
*æ–‡æ¡£åˆ›å»ºæ—¶é—´: {datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")}*
*æ•°æ®æ¥æº: çŸ¥è¯†æ˜Ÿçƒæ”¶è—å†…å®¹åˆ†æ*
"""
        return summary_template

    def _format_comprehensive_themes(self, themes: set) -> str:
        """æ ¼å¼åŒ–ç»¼åˆä¸»é¢˜"""
        if not themes:
            return "æœ¬æœŸæœªå‘ç°æ˜ç¡®çš„æ ¸å¿ƒæŠ•èµ„ä¸»é¢˜"

        formatted = ""
        for i, theme in enumerate(themes, 1):
            formatted += f"\n### {i}. {theme}\n"
            formatted += f"**æŠ•èµ„é€»è¾‘**: {self._get_theme_logic(theme)}\n"
            formatted += f"**é…ç½®æƒé‡**: {self._get_theme_weight(theme)}\n"
            formatted += f"**å…³é”®å‚¬åŒ–å‰‚**: {self._get_theme_catalysts(theme)}\n"

        return formatted

    def _format_comprehensive_strategy(self, themes: set) -> str:
        """æ ¼å¼åŒ–ç»¼åˆç­–ç•¥"""
        if not themes:
            return "å»ºè®®ä¿æŒå‡è¡¡é…ç½®ï¼Œå…³æ³¨å¸‚åœºè½®åŠ¨æœºä¼š"

        strategy = "**æ ¸å¿ƒé…ç½®ç»„åˆ** (100%ä»“ä½):\n\n"
        remaining_weight = 100

        for theme in themes:
            weight_str = self._get_theme_weight(theme)
            weight_num = int(weight_str.split('-')[0])
            strategy += f"#### {theme}æ¿å— ({weight_str})\n"
            strategy += f"- {self._get_theme_strategy(theme)}\n\n"
            remaining_weight -= weight_num

        if remaining_weight > 0:
            strategy += f"#### å…¶ä»–æœºä¼š ({remaining_weight}%)\n"
            strategy += "- å…³æ³¨å¸‚åœºçƒ­ç‚¹è½®åŠ¨ï¼Œä¿æŒé€‚åº¦çµæ´»æ€§\n"

        return strategy

    def _format_comprehensive_companies(self, companies: List[str]) -> str:
        """æ ¼å¼åŒ–ç»¼åˆå…¬å¸åˆ—è¡¨"""
        if not companies:
            return "æš‚æ— æ˜ç¡®é‡ç‚¹å…³æ³¨å…¬å¸"

        formatted = ""
        for i, company in enumerate(companies, 1):
            formatted += f"{i}. **{company}** - é‡ç‚¹å…³æ³¨\n"

        return formatted

    def _format_comprehensive_risks(self, risks: List[str]) -> str:
        """æ ¼å¼åŒ–ç»¼åˆé£é™©"""
        if not risks:
            return "1. å¸‚åœºç³»ç»Ÿæ€§é£é™©\n2. è¡Œä¸šæ”¿ç­–é£é™©\n3. å…¬å¸åŸºæœ¬é¢é£é™©"

        formatted = ""
        for i, risk in enumerate(risks, 1):
            formatted += f"{i}. **{risk}**: {self._get_risk_description(risk)}\n"

        return formatted

    def _get_risk_description(self, risk: str) -> str:
        """è·å–é£é™©æè¿°"""
        risk_desc = {
            "æ”¿ç­–é£é™©": "å›½é™…è´¸æ˜“æ‘©æ“¦ã€è¡Œä¸šç›‘ç®¡æ”¿ç­–å˜åŒ–å¯èƒ½å½±å“æŠ•èµ„é¢„æœŸ",
            "æŠ€æœ¯é£é™©": "æŠ€æœ¯çªç ´è¿›åº¦ä¸åŠé¢„æœŸï¼Œäº§ä¸šåŒ–è¿›ç¨‹å¯èƒ½å»¶ç¼“",
            "å¸‚åœºé£é™©": "è¡Œä¸šæ™¯æ°”åº¦æ³¢åŠ¨ï¼Œå¸‚åœºæƒ…ç»ªå˜åŒ–å½±å“ä¼°å€¼",
            "ä¼°å€¼é£é™©": "éƒ¨åˆ†æ ‡çš„ä¼°å€¼åé«˜ï¼Œå­˜åœ¨å›è°ƒå‹åŠ›"
        }
        return risk_desc.get(risk, "éœ€è¦å¯†åˆ‡å…³æ³¨ç›¸å…³é£é™©å› ç´ ")

    def _generate_tracking_points(self, themes: set) -> str:
        """ç”Ÿæˆè·Ÿè¸ªè¦ç‚¹"""
        points = [
            "**ä¸šç»©éªŒè¯**: å…³æ³¨Q3è´¢æŠ¥å­£ç›¸å…³å…¬å¸ä¸šç»©è¡¨ç°",
            "**æ”¿ç­–å‚¬åŒ–**: è·Ÿè¸ªè¡Œä¸šæ”¿ç­–å’Œæ”¯æŒæªæ–½è½åœ°æƒ…å†µ",
            "**æŠ€æœ¯è¿›å±•**: å…³æ³¨å…³é”®æŠ€æœ¯çªç ´å’Œäº§ä¸šåŒ–è¿›åº¦",
            "**å¸‚åœºè¶‹åŠ¿**: ç›‘æ§ä¸‹æ¸¸éœ€æ±‚å˜åŒ–å’Œè¡Œä¸šæ™¯æ°”åº¦",
            "**ä¼°å€¼æ°´å¹³**: è¯„ä¼°å¸‚åœºä¼°å€¼åˆç†æ€§ï¼ŒæŠŠæ¡ä¹°å…¥æ—¶æœº"
        ]

        return "\n".join([f"{i+1}. {point}" for i, point in enumerate(points)])

    def _generate_comprehensive_conclusion(self, themes: set, date_range: tuple) -> str:
        """ç”Ÿæˆç»¼åˆç»“è®º"""
        start_date, end_date = date_range
        theme_count = len(themes)

        if theme_count == 0:
            return "æœ¬æœŸæ”¶è—å†…å®¹ç›¸å¯¹åˆ†æ•£ï¼Œå»ºè®®ä¿æŒè°¨æ…è§‚æœ›ï¼Œå…³æ³¨å¸‚åœºä¸»çº¿æœºä¼šã€‚"
        elif theme_count <= 2:
            return f"æœ¬æœŸæŠ•èµ„ä¸»é¢˜ç›¸å¯¹é›†ä¸­ï¼Œå»ºè®®é‡ç‚¹é…ç½®{'/'.join(themes)}ç­‰æ ¸å¿ƒèµ›é“ï¼ŒæŠŠæ¡ç»“æ„æ€§æœºä¼šã€‚"
        else:
            return f"æœ¬æœŸæŠ•èµ„æœºä¼šå¤šå…ƒåŒ–ï¼Œæ¶µç›–{theme_count}ä¸ªä¸»è¦é¢†åŸŸï¼Œå»ºè®®å‡è¡¡é…ç½®ï¼Œå…³æ³¨è½®åŠ¨æœºä¼šã€‚"

    def run_analysis(self, start_date: str, end_date: str) -> None:
        """æ‰§è¡Œå®Œæ•´çš„æŠ•èµ„åˆ†ææµç¨‹"""
        print(f"ğŸš€ å¯åŠ¨æŠ•èµ„åˆ†æAgent")
        print(f"ğŸ“… åˆ†ææ—¶é—´èŒƒå›´: {start_date} - {end_date}")

        # ç¬¬ä¸€æ­¥ï¼šæå–å¸–å­æ•°æ®
        print("\nğŸ“Š ç¬¬ä¸€æ­¥ï¼šæå–æ”¶è—å¸–å­æ•°æ®...")
        posts = self.extract_posts_from_favorites(start_date, end_date)
        print(f"âœ… æˆåŠŸæå– {len(posts)} ä¸ªå¸–å­")

        # ç¬¬äºŒæ­¥ï¼šæŒ‰æ—¥æœŸåˆ†ç»„
        print("\nğŸ“‹ ç¬¬äºŒæ­¥ï¼šæŒ‰æ—¥æœŸåˆ†ç»„å¸–å­...")
        grouped_posts = self.group_posts_by_date(posts)
        print(f"âœ… åˆ†ç»„åˆ° {len(grouped_posts)} ä¸ªæ—¥æœŸ")

        # ç¬¬ä¸‰æ­¥ï¼šåˆ†ææ¯æ—¥å†…å®¹å¹¶ç”ŸæˆæŠ¥å‘Š
        print("\nğŸ“ ç¬¬ä¸‰æ­¥ï¼šç”Ÿæˆæ—¥åº¦åˆ†ææŠ¥å‘Š...")
        all_analysis = {}

        for date, daily_posts in sorted(grouped_posts.items()):
            print(f"  ğŸ“… åˆ†æ {date} ({len(daily_posts)} ä¸ªå¸–å­)")

            # åˆ†æå½“æ—¥å†…å®¹
            analysis = self.analyze_daily_themes(daily_posts)
            all_analysis[date] = analysis

            # ç”Ÿæˆæ—¥åº¦æŠ¥å‘Š
            report = self.generate_daily_report(date, daily_posts, analysis)

            # ä¿å­˜æŠ¥å‘Šæ–‡ä»¶
            filename = f"æŠ•èµ„æ”¶è—åˆ†æ-{date}.md"
            filepath = self.output_dir / filename

            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(report)

            print(f"  âœ… ç”ŸæˆæŠ¥å‘Š: {filename}")

        # ç¬¬å››æ­¥ï¼šç”Ÿæˆç»¼åˆæ±‡æ€»
        print("\nğŸ“Š ç¬¬å››æ­¥ï¼šç”Ÿæˆç»¼åˆæ±‡æ€»æŠ¥å‘Š...")
        summary = self.create_comprehensive_summary((start_date, end_date), all_analysis)

        summary_filename = f"æŠ•èµ„æ”¶è—åˆ†æ-{start_date}è‡³{end_date}ç»¼åˆæ±‡æ€».md"
        summary_filepath = self.output_dir / summary_filename

        with open(summary_filepath, 'w', encoding='utf-8') as f:
            f.write(summary)

        print(f"âœ… ç”Ÿæˆç»¼åˆæ±‡æ€»: {summary_filename}")

        # å®Œæˆæ€»ç»“
        print(f"\nğŸ‰ æŠ•èµ„åˆ†æå®Œæˆ!")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.output_dir}")
        print(f"ğŸ“Š æ—¥åº¦æŠ¥å‘Š: {len(all_analysis)} ä¸ª")
        print(f"ğŸ“‹ ç»¼åˆæ±‡æ€»: 1 ä¸ª")
        print(f"ğŸ’¡ ä¸»è¦æŠ•èµ„ä¸»é¢˜: {self._get_all_themes(all_analysis)}")

    def _get_all_themes(self, all_analysis: Dict[str, Dict]) -> str:
        """è·å–æ‰€æœ‰æŠ•èµ„ä¸»é¢˜"""
        all_themes = set()
        for analysis in all_analysis.values():
            all_themes.update(analysis.get('main_themes', []))
        return ', '.join(all_themes) if all_themes else 'ç»¼åˆæŠ•èµ„'


def main():
    """ä¸»å‡½æ•° - å‘½ä»¤è¡Œè°ƒç”¨ç¤ºä¾‹"""
    import sys

    if len(sys.argv) != 3:
        print("ä½¿ç”¨æ–¹æ³•: python investment_analysis_agent.py <å¼€å§‹æ—¥æœŸ> <ç»“æŸæ—¥æœŸ>")
        print("æ—¥æœŸæ ¼å¼: YYYY-MM-DD")
        print("ç¤ºä¾‹: python investment_analysis_agent.py 2025-09-12 2025-09-14")
        return

    start_date = sys.argv[1]
    end_date = sys.argv[2]

    # åˆ›å»ºAgentå¹¶æ‰§è¡Œåˆ†æ
    agent = InvestmentAnalysisAgent()
    agent.run_analysis(start_date, end_date)


if __name__ == "__main__":
    main()